{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from qgsw.fields.variables.tuples import UVH\n",
    "import numpy as np\n",
    "import torch\n",
    "from traitlets import default\n",
    "from qgsw.masks import Masks\n",
    "from qgsw.models.qg.stretching_matrix import compute_A, compute_layers_to_mode_decomposition\n",
    "from qgsw.models.qg.uvh.projectors.core import QGProjector\n",
    "from qgsw.output import RunOutput\n",
    "from qgsw.spatial.core.discretization import SpaceDiscretization3D\n",
    "from qgsw.spatial.core.grid_conversion import points_to_surfaces\n",
    "from qgsw.specs import defaults\n",
    "from qgsw.utils import covphys\n",
    "from scipy import signal\n",
    "from collections.abc import Iterable, Iterator\n",
    "\n",
    "from qgsw.output import OutputFileUVH\n",
    "from qgsw.plots.heatmaps import AnimatedHeatmaps\n",
    "from qgsw.filters.base import _Filter\n",
    "\n",
    "class NoFilter:\n",
    "    def __call__(self, to_filter: torch.Tensor) -> torch.Tensor:\n",
    "        return to_filter\n",
    "\n",
    "\n",
    "run = RunOutput(\"../output/g5k/sw_double_gyre_long_hr\")\n",
    "\n",
    "H = run.summary.configuration.model.h\n",
    "f0 = run.summary.configuration.physics.f0\n",
    "P = QGProjector(\n",
    "    A =compute_A(\n",
    "        H = H,\n",
    "        g_prime = torch.tensor([9.81,0.025, 0.0125],**defaults.get())\n",
    "    ),\n",
    "    H = H.unsqueeze(-1).unsqueeze(-1),\n",
    "    space=SpaceDiscretization3D.from_config(\n",
    "        run.summary.configuration.space,\n",
    "        run.summary.configuration.model\n",
    "    ),\n",
    "    f0 = run.summary.configuration.physics.f0,\n",
    "    masks = Masks.empty(nx=run.summary.configuration.space.nx,ny=run.summary.configuration.space.ny)\n",
    ")\n",
    "space=P.space\n",
    "\n",
    "y = torch.linspace(\n",
    "    0.5 * space.dy,\n",
    "    space.ly - 0.5 * space.dy,\n",
    "    space.ny,\n",
    "    **defaults.get()\n",
    ").unsqueeze(0)\n",
    "y0 = 0.5 * space.ly\n",
    "\n",
    "# Beta-effect\n",
    "beta_effect = run.summary.configuration.physics.beta * (y - y0)\n",
    "\n",
    "outputs = run.outputs()\n",
    "dx,dy = run.summary.configuration.space.dx, run.summary.configuration.space.dy\n",
    "nx,ny = run.summary.configuration.space.nx, run.summary.configuration.space.ny\n",
    "\n",
    "def compute_sf(uvh:UVH, P:QGProjector, dx:float, dy:float, filt:_Filter)-> torch.Tensor:\n",
    "    sf = P.compute_p(covphys.to_cov(uvh,dx,dy))[1][0]/P._f0\n",
    "    sf[0] = filt(sf[0])\n",
    "    sf[1] = filt(sf[1])\n",
    "    sf[2] = filt(sf[2])\n",
    "    return sf\n",
    "\n",
    "_ , _, Cl2m = compute_layers_to_mode_decomposition(P.A)\n",
    "\n",
    "def compute_modes(uvh:UVH, P:QGProjector, dx:float, dy:float, filt:_Filter)-> torch.Tensor:\n",
    "    sf = P.compute_p(covphys.to_cov(uvh,dx,dy))[1][0]/P._f0\n",
    "    return torch.einsum(\"...lm,...mxy->...lxy\", Cl2m, sf)\n",
    "\n",
    "\n",
    "def compute_pv(uvh:UVH, H:torch.Tensor, f0:float, dx:float, dy:float, filt:_Filter)-> torch.Tensor:\n",
    "    u,v,h = uvh.u, uvh.v, uvh.h\n",
    "    omega = torch.diff(v[..., 1:-1], dim=-2) / dx - torch.diff(u[..., 1:-1, :], dim=-1) / dy\n",
    "    h = points_to_surfaces(h)\n",
    "    pv =  (omega - f0 * h / H)[0]\n",
    "    pv[0] = filt(pv[0])\n",
    "    pv[1] = filt(pv[1])\n",
    "    pv[2] = filt(pv[2])\n",
    "    return pv\n",
    "\n",
    "def load_sf(outputs: Iterable[OutputFileUVH], P:QGProjector, dx:float, dy:float, filt:_Filter = NoFilter()) -> Iterator[torch.Tensor]:\n",
    "    return (compute_sf(o.read(), P, dx, dy, filt) for o in outputs)\n",
    "\n",
    "def load_modes(outputs: Iterable[OutputFileUVH], P:QGProjector, dx:float, dy:float, filt:_Filter = NoFilter()) -> Iterator[torch.Tensor]:\n",
    "    return (compute_modes(o.read(), P, dx, dy, filt) for o in outputs)\n",
    "\n",
    "\n",
    "def load_pv(outputs: Iterable[OutputFileUVH], H:torch.Tensor, f0:float,dx:float, dy:float, filt:_Filter = NoFilter()) -> Iterator[torch.Tensor]:\n",
    "    return (compute_pv(o.read(), H, f0, dx, dy, filt) for o in outputs)\n",
    "\n",
    "def compute_correlations(profiles: torch.Tensor, normalize_mean:bool = False) -> torch.Tensor:\n",
    "    nt, nx, ny = profiles.shape\n",
    "    stacked = profiles.reshape((nt, nx*ny))\n",
    "\n",
    "    correlation_nt = 2*nt-1\n",
    "    correlations = torch.zeros((correlation_nt,nx*ny))\n",
    "\n",
    "    Ns = np.array([366/(366-abs(i)) for i in range(-365,366)])\n",
    "\n",
    "    for i in range(nx*ny):\n",
    "        mean = np.mean(stacked[:,i])\n",
    "        timeseries = stacked[:,i] - mean\n",
    "        correlations_np = signal.correlate(timeseries,timeseries,mode=\"full\")\n",
    "        if normalize_mean:\n",
    "            correlations_np*=Ns\n",
    "        correlations[:,i]= torch.tensor(correlations_np)\n",
    "\n",
    "    normalized = correlations / correlations[correlation_nt//2]\n",
    "    sliced = normalized[correlation_nt//2:]\n",
    "    return torch.reshape(sliced, (nt, nx, ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlations(correlations:torch.Tensor, suptitle:str|None=None) -> None:\n",
    "\n",
    "    nt, nl, nx,ny = correlations.shape\n",
    "\n",
    "    nx_nb_slice, ny_nb_slice = 8,16\n",
    "    xs = [(max(0,int((i-1)*nx/nx_nb_slice)),min(nx-1,int(i*nx/nx_nb_slice))) for i in range(1,nx_nb_slice+1)]\n",
    "    ys = [(max(0,int((i-1)*ny/ny_nb_slice)),min(ny-1,int(i*ny/ny_nb_slice))) for i in range(1,ny_nb_slice+1)]\n",
    "    decorrelation_times = torch.sum(correlations,dim=0)\n",
    "    decorrelation_means = torch.zeros(decorrelation_times.shape)\n",
    "\n",
    "\n",
    "    fig_time_decorr, axs_time_decorr = plt.subplots(1,nl,squeeze=False, constrained_layout=True,figsize=(15,8))\n",
    "\n",
    "    fig_mean_decorr, axs_mean_decorr = plt.subplots(1,nl,squeeze=False, constrained_layout=True,figsize=(15,8))\n",
    "    \n",
    "    for xmin,xmax in xs:\n",
    "        for ymin,ymax in ys:\n",
    "            mean = torch.mean(decorrelation_times[...,xmin:xmax+1,ymin:ymax+1],dim=[-2,-1],keepdim=True)\n",
    "            decorrelation_means[:,xmin:xmax+1,ymin:ymax+1] = mean\n",
    "            axs_mean_decorr[0,0].text((xmin+xmax)//2,(ymin+ymax)//2,round(mean[0].item()),ha=\"center\",va=\"center\")\n",
    "            axs_mean_decorr[0,1].text((xmin+xmax)//2,(ymin+ymax)//2,round(mean[1].item()),ha=\"center\",va=\"center\")\n",
    "            axs_mean_decorr[0,2].text((xmin+xmax)//2,(ymin+ymax)//2,round(mean[2].item()),ha=\"center\",va=\"center\")\n",
    "    \n",
    "    fig_profiles, axs_profiles = plt.subplots(1,nl,squeeze=False, constrained_layout=True,figsize=(15,5))\n",
    "    \n",
    "    if suptitle is not None:\n",
    "        fig_time_decorr.suptitle(suptitle)\n",
    "        fig_mean_decorr.suptitle(suptitle)\n",
    "        fig_profiles.suptitle(suptitle)\n",
    "\n",
    "    for l in range(nl):\n",
    "\n",
    "        corr = correlations[:,l,...]\n",
    "        axs_time_decorr[0,l].set_title(f\"Layer {l}\")\n",
    "        cbar = axs_time_decorr[0,l].imshow(torch.sum(corr,dim=0).T,cmap=\"jet\")\n",
    "        fig_time_decorr.colorbar(cbar,ax=axs_time_decorr[0,l], label=\"Integral time scale [days]\")\n",
    "        axs_time_decorr[0,l].scatter(64,128, label=\"x=64, y=128\", c=\"b\")\n",
    "        axs_time_decorr[0,l].scatter(64,384, label=\"x=64, y=384\", c=\"r\" )\n",
    "        axs_time_decorr[0,l].scatter(128,256, label=\"x=128, y=256\", c = \"k\")\n",
    "        axs_time_decorr[0,l].scatter(192,128, label=\"x=192, y=128\", c=\"brown\")\n",
    "        axs_time_decorr[0,l].scatter(192,384, label=\"x=192, y=384\", c = \"orange\")\n",
    "\n",
    "        xs = [k for k in range(corr.shape[0])]\n",
    "        axs_profiles[0,l].set_title(f\"Layer {l}\")\n",
    "        axs_profiles[0,l].plot(xs, corr[:,64,128], label=\"x=64, y=128\", color=\"b\")\n",
    "        axs_profiles[0,l].plot(xs, corr[:,64,384], label=\"x=64, y=384\", color=\"r\" )\n",
    "        axs_profiles[0,l].plot(xs, corr[:,128,256], label=\"x=128, y=256\", color = \"k\")\n",
    "        axs_profiles[0,l].plot(xs, corr[:,192,128], label=\"x=192, y=128\", color=\"brown\")\n",
    "        axs_profiles[0,l].plot(xs, corr[:,192,384], label=\"x=192, y=384\", color = \"orange\")\n",
    "        axs_profiles[0,l].hlines(y=0,xmin=0,xmax=nt,linestyles=\"--\",colors=\"k\",alpha=0.25)\n",
    "        axs_profiles[0,l].vlines(x=20,ymin=-1,ymax=1,linestyles=\"--\",colors=\"k\",alpha=0.25)\n",
    "\n",
    "        axs_mean_decorr[0,l].set_title(f\"Layer {l}\")\n",
    "        cbar = axs_mean_decorr[0,l].imshow(decorrelation_means[l].T,cmap=\"jet\")\n",
    "        # fig_mean_decorr.colorbar(cbar,ax=axs_mean_decorr[0,l], label=\"Integral time scale [days]\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close(fig_time_decorr)\n",
    "    plt.close(fig_mean_decorr)\n",
    "    plt.close(fig_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_layers = []\n",
    "\n",
    "for layer in [0,1,2]:\n",
    "\n",
    "    data_3D = load_sf(run.outputs(), P, dx, dy)\n",
    "    data_stacked = torch.stack([e[layer] for e in data_3D],dim=0).cpu().numpy()\n",
    "\n",
    "    correlations_layer = compute_correlations(data_stacked)\n",
    "    corrs_layers.append(correlations_layer)\n",
    "correlations_full = torch.stack(corrs_layers,dim=1)\n",
    "\n",
    "correlations = correlations_full[:threshold]\n",
    "\n",
    "\n",
    "plot_correlations(correlations,\"Stream function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qgsw.filters.high_pass import GaussianHighPass2D\n",
    "\n",
    "\n",
    "corrs_layers_filt = []\n",
    "filt = GaussianHighPass2D(sigma=5)\n",
    "\n",
    "for layer in [0,1,2]:\n",
    "\n",
    "    data_3D_filt = load_sf(run.outputs(), P, dx, dy, filt)\n",
    "    data_stacked_filt = torch.stack([e[layer] for e in data_3D_filt],dim=0).cpu().numpy()\n",
    "\n",
    "    correlations_layer_filt = compute_correlations(data_stacked_filt)\n",
    "    corrs_layers_filt.append(correlations_layer_filt)\n",
    "correlations_full_filt = torch.stack(corrs_layers_filt,dim=1)\n",
    "\n",
    "correlations_filt = correlations_full_filt[:threshold]\n",
    "\n",
    "\n",
    "plot_correlations(correlations_filt,f\"Filtered stream function: σ = {filt.sigma}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_layers = []\n",
    "\n",
    "for layer in [0,1,2]:\n",
    "\n",
    "    data_3D = load_pv(run.outputs(), H.unsqueeze(-1).unsqueeze(-1), f0, dx, dy)\n",
    "    data_stacked = torch.stack([e[layer] for e in data_3D],dim=0).cpu().numpy()\n",
    "\n",
    "    correlations_layer = compute_correlations(data_stacked)\n",
    "    corrs_layers.append(correlations_layer)\n",
    "correlations_full = torch.stack(corrs_layers,dim=1)\n",
    "\n",
    "correlations = correlations_full[:threshold]\n",
    "\n",
    "\n",
    "plot_correlations(correlations,f\"Potential vorticity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qgsw.filters.high_pass import GaussianHighPass2D\n",
    "\n",
    "\n",
    "corrs_layers_filt = []\n",
    "filt = GaussianHighPass2D(sigma=30)\n",
    "\n",
    "for layer in [0,1,2]:\n",
    "\n",
    "    data_3D_filt = load_pv(run.outputs(), H.unsqueeze(-1).unsqueeze(-1), f0, dx, dy, filt)\n",
    "    data_stacked_filt = torch.stack([e[layer] for e in data_3D_filt],dim=0).cpu().numpy()\n",
    "\n",
    "    correlations_layer_filt = compute_correlations(data_stacked_filt)\n",
    "    corrs_layers_filt.append(correlations_layer_filt)\n",
    "correlations_full_filt = torch.stack(corrs_layers_filt,dim=1)\n",
    "\n",
    "correlations_filt = correlations_full_filt[:threshold]\n",
    "\n",
    "plot_correlations(correlations_filt,f\"Filtered potential vorticity: σ = {filt.sigma}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from qgsw.plots import plt_wrapper\n",
    "\n",
    "s = torch.sign(correlations)\n",
    "c = torch.clone(correlations)\n",
    "c[c<0] = np.nan\n",
    "idx = torch.nonzero(np.bitwise_not(torch.isnan(c)))\n",
    "\n",
    "idx =torch.argmax(-c,dim=0)\n",
    "\n",
    "fig = plt.figure(figsize=(5,8))\n",
    "ax = fig.add_subplot()\n",
    "cbar = ax.imshow(idx[0].T,vmin=0,cmap=plt_wrapper.DEFAULT_CMAP)\n",
    "fig.colorbar(cbar,ax=ax)\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "\n",
    "plt.hist(idx[0].ravel(),bins=100,density=True)\n",
    "plt.title(\"'first 0 correlation reached' timestep\")\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.xlabel(\"Time offset [days]\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "idx_np = idx[0].numpy()\n",
    "x = np.array([k for k in range(correlations.shape[0])])\n",
    "y = np.array([np.sum(idx_np == k) for k in x])\n",
    "y_cumsum = np.cumsum(y)\n",
    "plt.plot(x,y_cumsum/nx/ny*100)\n",
    "plt.ylabel(\"% of data\")\n",
    "plt.xlabel(\"Time offset [days]\")\n",
    "plt.vlines(x=20,color='red', linestyles='--', ymin=0,ymax=100,alpha=0.25,label=\"20 days\")\n",
    "plt.title(\"Cumulative proportion of 'first 0 correlation reached' timestep\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_stacked[50:,10, 20] - np.mean(data_stacked[:,10,20])\n",
    "y = data_stacked[:-50,10, 20] - np.mean(data_stacked[:,10,20])\n",
    "x0 = data_stacked[:,10,20] - np.mean(data_stacked[:,10,20])\n",
    "np.sum(x*y)/np.sum(x0*x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations[50,2,10,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot = AnimatedHeatmaps([[sf_correlations[i,0].T for i in range(threshold)]])\n",
    "# plot.set_zbounds(-1,1)\n",
    "# ts = [f\"Offset: {o.read().t.item() / 3600 / 24:.1f} day(s)\" for o in run.outputs()][:threshold]\n",
    "# plot.set_frame_labels(ts)\n",
    "# plot.save_video(\"../output/video/autocorrelation_sf.mp4\",width=512,height=1024,fps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
